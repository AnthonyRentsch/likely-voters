---
title: "Cutoff Models"
date: "2017-11-27"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, echo = FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::read_chunk('load.R')
```

```{r, echo = FALSE, include = FALSE}
# run load.R 
<<load>> 
```

# Introduction

In this document, I will define and create the cutoff models that I will use for my analysis and then evaluate their performance. The sections will proceed as follows:

* Vote intent
* Vote intent + vote history
* Perry-Gallup index
* Logistic regression
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
* Random forests
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
  
In each section I will create a model and then evaluate how well it predicts voting behavior on an individual-level using a simulation-based approach. At the end, I will use these models to make election predictions.



# Vote Intent

For now, I am doing this for 2016 until I can create the pooled data set. Here I treat people who report that they have already voted the same as people who report that they definitely plan to vote. Note that the weight I use -- `commonweight` from the `cces16` data -- combines weights based on age, gender, education, race, voter registration, ideology, baseline party identification, born again status, and political interest.


```{r}
# grab data and filter only those with valid vote intent responses
data <- cces16 %>% select(V101, state_abbreviation, CC16_364, CC16_364b, CC16_364c,  
                          CL_E2016GVM, commonweight) %>% 
  rename(ID = V101, state = state_abbreviation, intent = CC16_364, earlychoice = CC16_364b, 
         choice = CC16_364c, validated = CL_E2016GVM, weight = commonweight) %>% 
  filter(intent %in% c(1,2,3,4,5))

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))
```



## Individual-level turnout

```{r}
validation_by_intent <- function(intention){
  willvote <- data %>% 
    filter(intent %in% intention)
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First we compare individual-level turnout prediction accuracy when we define likely voters as:

* those who say they already voted
* those who say they will definitely vote or have voted already
* those who say they will definitely vote, have voted already, or will probably vote
* those who say they will definitely vote, have voted already, will probably vote, or who are undecided
* all respondents in the sample

Let's sum that all up, where

* true positive rate = rate at which predicted voters are validated as voters
* true negative rate = rate at which predicted nonvoters are not validated as voters

```{r, echo = FALSE, warning = FALSE}
# those who say they already voted
mod1 <- validation_by_intent(3)
# those who say they will definitely vote or have voted already
mod2 <- validation_by_intent(c(1,3))
# those who say they will definitely vote, have voted already, or will probably vote
mod3 <- validation_by_intent(c(1,2,3))
# those who say they will definitely vote, have voted already, will probably vote, or who are undecided
mod4 <- validation_by_intent(c(1,2,3,5))
# all respondents in the sample
mod5 <- validation_by_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4, mod5)

df <- data.frame(model = c("Already voted", "Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 5),
                 #false_positive = vector(length = 5),
                 #false_negative = vector(length = 5),
                 true_negative = vector(length = 5))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  #df$false_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "No"]
  #df$false_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Individual level vote validation by vote intent model") +
  scale_fill_grey()
```


## Election predictions


```{r}
vote_choice_intent <- function(intention){
  data %>% 
  filter(intent %in% intention) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}
```

Now we compare election predictions, using the same likely voter models as specified above.

```{r, echo = FALSE}
mod1 <- vote_choice_intent(c(1,3))
mod2 <- vote_choice_intent(c(1,2,3))
mod3 <- vote_choice_intent(c(1,2,3,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents", "Actual result"),
                 margin = vector(length = 5))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df$margin[5] <- 2.1

df$model <- factor(df$model, levels = df$model)

df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  labs(y = "Clinton's predicted margin of victory")
```



# Vote Intent + Vote History

Let's move on to the next baseline model - using vote history and vote intent. I follow the same template from above but consider what happens when likely voters are defined as individuals who report that they voted in the previous presidential election (2012) as well as what happens when we do not make that distinction.

```{r, echo = FALSE}
# grab data and filter only those with valid vote intent and vote history responses
data <- cces16 %>% select(V101, state_abbreviation, CC16_364, CC16_364b, CC16_364c, CC16_326,  
                          CL_E2016GVM, commonweight) %>% 
  rename(ID = V101, state = state_abbreviation, intent = CC16_364, earlychoice = CC16_364b, 
         choice = CC16_364c, vote12 = CC16_326, validated = CL_E2016GVM, weight = commonweight) %>% 
  filter(intent %in% c(1,2,3,4,5)) %>% 
  filter(vote12 %in% c(1,2,3,4,5))

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))
```

## Individual-level turnout

```{r, echo = FALSE}
validation_intent_history <- function(intention, history){
  willvote <- data %>% 
    filter(intent %in% intention, vote12 %in% history)
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First, I'll consider everyone who self-reported that they voted in 2012. Note that this will necessarily exclude any respondent who was too young to vote in 2012 (unless they lie on this question, of course).

```{r, echo = FALSE, warning = FALSE}
mod1 <- validation_intent_history(c(1,3), c(1,2,3))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Voted in 2012") +
  scale_fill_grey()
```

```{r, echo = FALSE, warning = FALSE}
mod1 <- validation_intent_history(c(1,3), c(1,2,3,5))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3,5))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3,5))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Voted in 2012 or don't recall") +
  scale_fill_grey()
```

```{r, echo = FALSE, warning = FALSE}
mod1 <- validation_intent_history(c(1,3), c(1,2,3,4,5))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3,4,5))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3,4,5))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Voted in 2012, don't recall, or didn't vote") +
  scale_fill_grey()
```

Might be useful to make a table with this, as this is a lot to take in visually.

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_intent <- function(intention, history){
  data %>% 
  filter(intent %in% intention, vote12 %in% history) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}
```

```{r, echo = FALSE}
# voted in 2012
mod1 <- vote_choice_intent(c(1,3), c(1,2,3))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3))

mods <- list(mod1, mod2, mod3, mod4)

df1 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df1$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice=="Trump"]
  i = i + 1
}

df1$model <- factor(df1$model, levels = df1$model)

# voted in 2012 or don't recall
mod1 <- vote_choice_intent(c(1,3), c(1,2,3,5))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3,5))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3,5))

mods <- list(mod1, mod2, mod3, mod4)

df2 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df2$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df2$model <- factor(df2$model, levels = df2$model)

# voted in 2012, don't recall, or did not vote
mod1 <- vote_choice_intent(c(1,3), c(1,2,3,4,5))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3,4,5))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3,4,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df3 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df3$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df3$model <- factor(df3$model, levels = df3$model)
```

```{r, echo = FALSE, warning = FALSE}
df_combined <- join_all(list(df1, df2, df3), by = "model")
names(df_combined) <- c("model", "Voted in 2012", "Voted in 2012 or didn't recall", "All")

df_combined %>% gather(`Vote history`, value, `Voted in 2012`:All) %>%  
  ggplot(aes(factor(model), value, fill = `Vote history`)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 45, hjust = 1)) +
  coord_flip() +
  labs(x = "Vote intent", y = "Clinton's predicted margin of victory") +
  scale_fill_grey() +
  geom_hline(yintercept = 2.1, lty = 2, colour = "red")
```

My takeaway is that adding vote history does not add much information on top of vote intent. But this is just for 2016 election predictions - may be useful to predict individual-level turnout and may be useful for other elections still.


# Perry-Gallup index

In their 2016 report on likely voter methodology, the Pew Research Center uses the Perry-Gallup index to measure likelyhood to vote. The questions they use, as well as the response options, are listed below. Response options that are bolded give a respondent a point in the index.

* How much thought have you given to the coming November election? **Quite a lot**, **some**, only a little, none.
* Have you ever voted in your precinct or election district? **Yes**, no.
* Would you say you follow whatâ€™s going on in government and public affairs **most of the time**, **some of the time**, only now and then, hardly at all?
* How often would you say you vote? **Always**, **nearly always**, part of the time, seldom.
* How likely are you to vote in the general election this November? **Definitely will vote**,
**probably will vote**, probably will not vote, definitely will not vote.
* In the 2012 presidential election between Barack Obama and Mitt Romney, did things come up
that kept you from voting, or did you happen to vote? **Yes, voted**; no.
* Please rate your chance of voting in November on a scale of 10 to 1. 0-8, **9**, **10**.

Since the common content of the CCES does not include all of these survey items (and question wording varies when they do appear), I will attempt to recreate the index using what is available to me. 

The three variables I will consider are vote intent, vote history, and political interest, which capture 5 of the 7 items on the Perry-Gallup index. The one dimension that I will not be able to recreate is historical voting behavior (voted in precinct before, voting frequency), as this information is not available on the CCES. Here are the CCES questions I will use along with the response options, and how many points each response option gives an individual toward the index. 

* Do you intend to vote in 2016 general election?
    + Yes, definitely (**+2**)
    + Probably (**+1**)
    + I already voted (early or absentee) (**+2**)
    + No
    + Undecided
* In 2012, who did you vote for in the election for President?
    + Barack Obama (**+1**)
    + Mitt Romney (**+1**)
    + Someone else (**+1**)
    + Did not vote
    + Don't recall
* Some people seem to follow what is going on in government or public affairs most of the time, whether there's an election or not. Others aren't that interested. Would you say you follow what is going on in government and public affairs...
    + Most of the time (**+2**)
    + Some of the time (**+1**)
    + Only now and then
    + Hardly at all
    + Don't know

There are two further adjustments I make. First, Pew samples off of a list of registered voters, which the CCES does not do. To compensate, respondents who report that they are registered to vote are given an additional point. Second, since respondents who are younger than 22 would not have had the chance to vote in the previous election, they are given one additional point.

The minimum score, corresponding to those least likely to vote, is 0 while the maximum score, corresponding to those most likely to vote, is 6.

```{r, warning = FALSE}
data <- cces16 %>% select(V101, state_abbreviation, CC16_364b, CC16_364c,  
                          CL_E2016GVM, commonweight, CC16_326, CC16_364, newsint, birthyr, votereg) %>% 
  rename(ID = V101, state = state_abbreviation, earlychoice = CC16_364b, choice = CC16_364c, 
         validated = CL_E2016GVM, weight = commonweight, vote12 = CC16_326, intent = CC16_364, 
         interest = newsint, birthyr = birthyr, registration = votereg) %>% 
  mutate(age = 2016 - birthyr) %>% 
  select(-birthyr)

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))

# calculate Perry-Gallup index
data <- data %>% mutate(perry_gallup = 0)

# vote intent
data$perry_gallup[data$intent == 1 | data$intent == 3] <- data$perry_gallup + 2
data$perry_gallup[data$intent == 2]  <- data$perry_gallup + 1

# vote history
data$perry_gallup[data$vote12 == 1 | data$vote12 == 2 | data$vote12 == 3] <- data$perry_gallup + 1

# political interest
data$perry_gallup[!is.na(data$interest) && data$interest == 1] <- data$perry_gallup + 2
data$perry_gallup[!is.na(data$interest) && data$interest == 2] <- data$perry_gallup + 1

# voter registration 
data$perry_gallup[data$registration == 1] <- data$perry_gallup + 1

# age adjustment
data$perry_gallup[data$age < 22 && (data$vote12 == 4 | data$vote12 == 5 | 
                                      data$vote12 == 8 | data$vote12 == 9)] <- data$perry_gallup + 1
```

## Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
validation_by_pg <- function(index) {
  willvote <- data %>% 
    filter(perry_gallup %in% index)
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
mod1 <- validation_by_pg(6)
mod2 <- validation_by_pg(c(6,5))
mod3 <- validation_by_pg(c(6,5,4))
mod4 <- validation_by_pg(c(6,5,4,3))
mod5 <- validation_by_pg(c(6,5,4,3,2))
mod6 <- validation_by_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All"),
                 true_positive = vector(length = 6),
                 true_negative = vector(length = 6))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Individual level vote validation by Perry-Gallup index score") +
  scale_fill_grey()
```

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_pg <- function(index){
  data %>% 
  filter(perry_gallup %in% index) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

mod1 <- vote_choice_pg(6)
mod2 <- vote_choice_pg(c(6,5))
mod3 <- vote_choice_pg(c(6,5,4))
mod4 <- vote_choice_pg(c(6,5,4,3))
mod5 <- vote_choice_pg(c(6,5,4,3,2))
mod6 <- vote_choice_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All","Actual result"),
                 margin = vector(length = 7))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df$margin[7] <- 2.1

df$model <- factor(df$model, levels = df$model)

df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  labs(y = "Clinton's predicted margin of victory")
```



# Logistic regression


```{r, warning = FALSE, message = FALSE, echo = FALSE}
data <- cces16 %>% select(V101, state_abbreviation, CC16_364b, CC16_364c,  
                          CL_E2016GVM, commonweight, CC16_326, CC16_364, newsint, birthyr, gender,
                          racial_group, educ, faminc, pid7, pew_churatd, marstat, citylength_2,
                          CC16_300b, CC16_300c, votereg) %>% 
  rename(ID = V101, state = state_abbreviation, earlychoice = CC16_364b, choice = CC16_364c, 
         validated = CL_E2016GVM, weight = commonweight, vote12 = CC16_326, intent = CC16_364, 
         interest = newsint, birthyr = birthyr, gender = gender, race = racial_group, education = educ,
         income = faminc, partisanship = pid7, religiosity = pew_churatd, marital_status = marstat,
         residential_mobility = citylength_2, watch_news = CC16_300b, read_paper = CC16_300c, 
         registration = votereg) %>% 
  mutate(age = 2016 - birthyr) %>% 
  select(-birthyr)

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))

# calculate Perry-Gallup index
data <- data %>% mutate(perry_gallup = 0)

# vote intent
data$perry_gallup[data$intent == 1 | data$intent == 3] <- data$perry_gallup + 2
data$perry_gallup[data$intent == 2]  <- data$perry_gallup + 1

# vote history
data$perry_gallup[data$vote12 == 1 | data$vote12 == 2 | data$vote12 == 3] <- data$perry_gallup + 1

# political interest
data$perry_gallup[!is.na(data$interest) && data$interest == 1] <- data$perry_gallup + 2
data$perry_gallup[!is.na(data$interest) && data$interest == 2] <- data$perry_gallup + 1

# age adjustment
data$perry_gallup[data$age < 22 && (data$vote12 == 4 | data$vote12 == 5 | 
                                      data$vote12 == 8 | data$vote12 == 9)] <- data$perry_gallup + 1
# change validated variables values
data <- data %>% 
  mutate(validated = !is.na(validated)) %>% 
  mutate(validated = replace(validated, validated == "FALSE", 0)) %>% 
  mutate(validated = replace(validated, validated == "TRUE", 1))
```


Now I'll move onto building a logistic regression model to measure an individual's likelihood of voting. I'll do this using two sets of variables:

* Perry-Gallup index
* Perry-Gallup index + all variables potentially related to turnout

I will also be considering a model that includes variables typically included in structural election forecasting models, but while I am just using the 2016 data I cannot do this. Note that I made an age adjustment in the previous section but I do not consider age when I run the model that strictly considers questions that form the Perry-Gallup index.

## Perry-Gallup index

### Building model

```{r, warning = FALSE, message = FALSE}
# split data into training and test sets
set.seed(16)
train <- data %>% sample_frac(0.7)
test <- data %>% anti_join(train, by = "ID")

# exclude Rs who weren't asked these questions in train...
train <- train[train$vote12 < 8,] 
train <- train[train$intent < 8,]
train <- train[train$interest < 8,]

# ... and test
test <- test[test$vote12 < 8,] 
test <- test[test$intent < 8,]
test <- test[test$interest < 8,]

# recode vote12 so that we capture whether someone voted or not and not for who for train...
train$vote12[train$vote12 == 1 | train$vote12 == 2 | train$vote12 == 3] <- 1
train$vote12[train$vote12 == 4 | train$vote12 == 5] <- 2

# ... and test
test$vote12[test$vote12 == 1 | test$vote12 == 2 | test$vote12 == 3] <- 1
test$vote12[test$vote12 == 4 | test$vote12 == 5] <- 2

# recode interest to put 'Don't know' responses as 'Hardly at all'
train$interest[train$interest == 7] <- 4
test$interest[test$interest == 7] <- 4

# set all categorical variables as factors
train <- train %>% mutate(validated = as.factor(validated),
                 intent = as.factor(intent),
                 interest = as.factor(interest),
                 registration = as.factor(registration))
test <- test %>% mutate(validated = as.factor(validated),
                 intent = as.factor(intent),
                 interest = as.factor(interest),
                 registration = as.factor(registration))

# run model
formula <- as.formula(validated ~ vote12 + intent + interest + registration)
model <- glm(formula, data = train, family = "binomial")

# apply the model to test data
predictions <- model %>% 
  broom::augment(newdata = test) %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = p_hat), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = .99, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    arrange(desc(p_hat)) %>% 
    top_n(round(nrow(predictions)*turnout,0))
  wontvote <- predictions %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = (validated == 1)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 1)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, colour = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative,  colour = "True negative")) +
  #geom_vline(xintercept = 0.602*100, lty = 2) + (actual turnout rate for 2016 presidential election)
  labs(title = "True positive and true negative rates for holdout sample",
       x = "Turnout rate (%)",
       y = "",
       col = "Type")
```

As we consider a larger turnout rate, our true negative rate (rate that nonvoters get predicted to be nonvoters) goes up while our true positive rate (rate at which voters get predicted to be voters) goes down. This makes sense. 

What's trickier is figuring out where to strike the right balance between the two rates. To do this, we also need to look at the election predictions that likely voter models using different turnout rates produce.


### Election predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
vote_choice_logreg <- function(turnout){
  predictions %>% 
  arrange(desc(p_hat)) %>% 
  top_n(round(nrow(predictions)*turnout,0)) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=="Clinton"] - temp$vote_share[temp$choice=="Trump"]
   margin_by_turnout[i,2] <- i
   i = i +1
}

margin_by_turnout %>% 
  rename(margin = V1, i = V2) %>% 
  ggplot() +
  geom_point(aes(x = turnout_rates[i]*100, y = margin), alpha = 0.25) +
  geom_hline(yintercept = 2.1, lty = 2, col = "red") +
  #coord_cartesian(xlim = c(25, 100)) +
  labs(title = "Clinton's predicted margin of victory computed from holdput sample",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory")
```

This does not fit with what I would have believed before - I would have guessed, based on the findings of the other models, that more likely voters would have voted overwhelmingly for Clinton. Maybe what this model is contrary to all those findings (which is OK). This suggests that using a likely voter model with a turnout rate between 2% and 54% would have *nearly* perfectly predicted the final margin. Note: dots are predicted margins for each turnout rate while the blue line is a LOESS smoothed line fit to the points.

## Perry-Gallup + all variables potentially related to turnout

I will essentially repeat the process from above, but now the logistic regression model will consider *11* demographic variables that literature on voter turnout has suggested are correlated to turnout. Those variables are:

* Gender
* Age
* Race
* Education
* Family income
* Partisan/ideological strength
* Religiosity
* ~~Racial composition of district~~ **Not available on CCES**
* Marital status
* Residential mobility
* Political interest/activism
    + Watch news
    + Read paper

Note that this list should not be viewed as comprehensive - it reflects the research that I conducted for this project and it is possible that I have missed potentially important variables. Furthermore, note that the inclusion of the political interest/activism items about watching the news or reading the paper reduces the training sample by nearly 20k respondents (33,222 \rightarrow 13,474) and the test sample by roughly 9k respondents (14,464 \rightarrow 5,687).

### Building model

```{r, warning = FALSE, echo = FALSE, message = FALSE}
set.seed(17)
train <- data %>% sample_frac(0.7)
test <- data %>% anti_join(train, by = "ID")

# exclude Rs who weren't asked these questions in train...
train <- train[train$vote12 < 8,] 
train <- train[train$intent < 8,]
train <- train[train$interest < 8,]
train <- train[!train$income %in% c(98,99),]
train <- train[!train$partisanship %in% c(8, 98, 99),]
train <- train[!train$religiosity %in% c(8,9,12) & !is.na(train$religiosity),]
train <- train[!train$marital_status %in% c(8,9),]
train <- train[!is.na(train$residential_mobility) & train$residential_mobility >= 0,]
train <- train[!train$watch_news %in% c(8,9),]
train <- train[!train$read_paper %in% c(8,9),]

# ... and test
test <- test[test$vote12 < 8,] 
test <- test[test$intent < 8,]
test <- test[test$interest < 8,]
test <- test[!test$income %in% c(98,99),]
test <- test[!test$partisanship %in% c(8, 98, 99),]
test <- test[!test$religiosity %in% c(8,9,12) & !is.na(test$religiosity),]
test <- test[!test$marital_status %in% c(8,9),]
test <- test[!is.na(test$residential_mobility) & test$residential_mobility >= 0,]
test <- test[!test$watch_news %in% c(8,9),]
test <- test[!test$read_paper %in% c(8,9),]

# recode vote12 so that we capture whether someone voted or not and not for who for train...
train$vote12[train$vote12 == 1 | train$vote12 == 2 | train$vote12 == 3] <- 1
train$vote12[train$vote12 == 4 | train$vote12 == 5] <- 2

# ... and test
test$vote12[test$vote12 == 1 | test$vote12 == 2 | test$vote12 == 3] <- 1
test$vote12[test$vote12 == 4 | test$vote12 == 5] <- 2

# recode partisanship to capture partisan strength rather than Democrat v. Republican for train...
train$partisan_strength[train$partisanship %in% c(1,7)] <- 1 #very strong
train$partisan_strength[train$partisanship %in% c(2,6)] <- 2 #strong
train$partisan_strength[train$partisanship %in% c(3,5)] <- 3 #moderate
train$partisan_strength[train$partisanship == 4] <- 4 #weak

# ... and test
test$partisan_strength[test$partisanship %in% c(1,7)] <- 1 #very strong
test$partisan_strength[test$partisanship %in% c(2,6)] <- 2 #strong
test$partisan_strength[test$partisanship %in% c(3,5)] <- 3 #moderate
test$partisan_strength[test$partisanship == 4] <- 4 #weak

# recode interest to put 'Don't know' responses as 'Hardly at all'
train$interest[train$interest == 7] <- 4
test$interest[test$interest == 7] <- 4

# recode income for train...
train$income_new[train$income %in% c(1,2,3,4)] <- 1 #under 40k
train$income_new[train$income %in% c(5,6,7,8,9)] <- 2 #40 to 10k
train$income_new[train$income %in% c(10,11,12,13,14,15,16,31,32)] <- 3 #over 100k
train$income_new[train$income == 97] <- 4 #prefer not to say

# ... and test
test$income_new[test$income %in% c(1,2,3,4)] <- 1 #under 40k
test$income_new[test$income %in% c(5,6,7,8,9)] <- 2 #40 to 10k
test$income_new[test$income %in% c(10,11,12,13,14,15,16,31,32)] <- 3 #over 100k
test$income_new[test$income == 97] <- 4 #prefer not to say

# recode race
train$race[train$race %in% c(7,8)] <- 6 #send Middle Eastern and Mixed to Other
test$race[test$race %in% c(7,8)] <- 6

# recode marital status
train$marital_status[train$marital_status %in% c(2,3,4,6)] <- 3 #other
train$marital_status[train$marital_status == 5] <- 2 #single
test$marital_status[test$marital_status %in% c(2,3,4,6)] <- 3 #other
test$marital_status[test$marital_status == 5] <- 2 #single

# set all categorical variables as factors
train <- train %>% mutate(validated = as.factor(validated),
                 intent = as.factor(intent),
                 interest = as.factor(interest),
                 registration = as.factor(registration),
                 gender = as.factor(gender),
                 race = as.factor(race),
                 education = as.factor(education),
                 income_new = as.factor(income_new),
                 partisan_strength = as.factor(partisan_strength),
                 religiosity = as.factor(religiosity),
                 marital_status = as.factor(marital_status),
                 watch_news = as.factor(watch_news),
                 read_paper = as.factor(read_paper))

test <- test %>% mutate(validated = as.factor(validated),
                 intent = as.factor(intent),
                 interest = as.factor(interest),
                 registration = as.factor(registration),
                 gender = as.factor(gender),
                 race = as.factor(race),
                 education = as.factor(education),
                 income_new = as.factor(income_new),
                 partisan_strength = as.factor(partisan_strength),
                 religiosity = as.factor(religiosity),
                 marital_status = as.factor(marital_status),
                 watch_news = as.factor(watch_news),
                 read_paper = as.factor(read_paper))
```

```{r, warning = FALSE, message = FALSE}
# run model
formula <- as.formula(validated ~ vote12 + intent + interest + registration + gender + age + race + 
                        education + income_new + partisan_strength + religiosity + marital_status +
                        residential_mobility + watch_news + read_paper)
model <- glm(formula, data = train, family = "binomial")

# apply the model to test data
predictions <- model %>%
  broom::augment(newdata = test) %>%
  as_tibble() %>%
  mutate(p_hat = 1/(1 + exp(-.fitted)))
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = p_hat), position = "identity", bins = 30) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
true_pos_neg_rates_by_turnout %>%
  rename(true_positive = V1, true_negative = V2, i = V3) %>%
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, colour = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative,  colour = "True negative")) +
  #geom_vline(xintercept = 0.602*100, lty = 2) + (actual turnout rate for 2016 presidential election)
  labs(title = "True positive and true negative rates for holdout sample",
       x = "Turnout rate (%)",
       y = "",
       colour = "Type")
```



### Election predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=="Clinton"] - temp$vote_share[temp$choice=="Trump"]
   margin_by_turnout[i,2] <- i
   i = i +1
}

margin_by_turnout %>%
  rename(margin = V1, i = V2) %>%
  ggplot() +
  geom_point(aes(x = turnout_rates[i]*100, y = margin), alpha = 0.25) +
  geom_hline(yintercept = 2.1, lty = 2, col = "red") +
  coord_cartesian(xlim = c(25, 100)) +
  labs(title = "Clinton's predicted margin of victory computed from holdput sample",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory")
```

Using this model, most accurate prediction would have been given using a **really** low turnout rate - 33%.

# Random Forests