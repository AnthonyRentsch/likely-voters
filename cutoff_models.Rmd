---
title: "Analysis Part I - Cutoff Models"
date: "February 6, 2018"
output:
  github_document:
    toc: true
    #toc_float: true
    toc_depth: 2
    #collapsed: false
    #smooth_scroll: false
    df_print: kable
---

```{r setup, echo = FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::read_chunk('load.R')
```

```{r, echo = FALSE, include = FALSE}
# run load.R 
<<load>> 
```

# Introduction

In this document, I will define and create the cutoff models that I will use for my analysis and then evaluate their performance. The sections will proceed as follows:

* Vote intent
* Vote intent + vote history
* Perry-Gallup index
* Logistic regression
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
* Random forests
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
  
In each section I will create a model and then evaluate how well it predicts voting behavior on an individual-level. At the end, I will use these models to make election predictions.



# Vote Intent

For this section (and the next two), I only need to use 2016 data until. I treat people who report that they have already voted the same as people who report that they definitely plan to vote. Note that the weight I use -- `commonweight` from the `cces16` data -- combines weights based on age, gender, education, race, voter registration, ideology, baseline party identification, born again status, and political interest.


```{r, echo = FALSE}
# grab data and filter only those with valid vote intent responses
data <- cces16 %>% select(V101, state_abbreviation, CC16_364, CC16_364b, CC16_364c,  
                          CL_E2016GVM, commonweight) %>% 
  rename(ID = V101, state = state_abbreviation, intent = CC16_364, earlychoice = CC16_364b, 
         choice = CC16_364c, validated = CL_E2016GVM, weight = commonweight) %>% 
  filter(intent %in% c(1,2,3,4,5))

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))
```



## Individual-level turnout

```{r, echo = FALSE}
validation_by_intent <- function(intention){
  willvote <- data %>% 
    filter(intent %in% intention)
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First we compare individual-level turnout prediction accuracy when we define likely voters as:

* those who say they already voted
* those who say they will definitely vote or have voted already
* those who say they will definitely vote, have voted already, or will probably vote
* those who say they will definitely vote, have voted already, will probably vote, or who are undecided
* all respondents in the sample

where:

* true positive rate = rate at which predicted voters are validated as voters
* true negative rate = rate at which predicted nonvoters are not validated as voters

```{r, echo = FALSE, warning = FALSE}
# those who say they already voted
mod1 <- validation_by_intent(3)
# those who say they will definitely vote or have voted already
mod2 <- validation_by_intent(c(1,3))
# those who say they will definitely vote, have voted already, or will probably vote
mod3 <- validation_by_intent(c(1,2,3))
# those who say they will definitely vote, have voted already, will probably vote, or who are undecided
mod4 <- validation_by_intent(c(1,2,3,5))
# all respondents in the sample
mod5 <- validation_by_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4, mod5)

df <- data.frame(model = c("Already voted", "Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 5),
                 #false_positive = vector(length = 5),
                 #false_negative = vector(length = 5),
                 true_negative = vector(length = 5))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  #df$false_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "No"]
  #df$false_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Individual level vote validation by vote intent") +
  scale_fill_grey()
```


## Election predictions


```{r, echo = FALSE}
vote_choice_intent <- function(intention){
  data %>% 
  filter(intent %in% intention) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}
```

Now we compare election predictions, using the same likely voter models as specified above.

```{r, echo = FALSE}
mod1 <- vote_choice_intent(c(1,3))
mod2 <- vote_choice_intent(c(1,2,3))
mod3 <- vote_choice_intent(c(1,2,3,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df$model <- factor(df$model, levels = df$model)

df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  geom_hline(yintercept = 2.1, lty = 2, colour = "red") +
  labs(y = "Clinton's predicted margin of victory")
```



# Vote Intent + Vote History

Let's move on to the next baseline model - using vote history and vote intent. I follow the same template from above but consider what happens when likely voters are defined as individuals who report that they voted in the previous presidential election (2012) as well as what happens when we do not make that distinction. I also consider defining likely voters as voters who were validated as voters in 2012.

Note that this will necessarily exclude any respondent who was too young to vote in 2012 (unless they lie on this question, of course).

```{r, echo = FALSE}
# grab data and filter only those with valid vote intent and vote history responses
data <- cces16 %>% select(V101, state_abbreviation, CC16_364, CC16_364b, CC16_364c, CC16_326,  
                          CL_E2016GVM, commonweight, birthyr) %>% 
  rename(ID = V101, state = state_abbreviation, intent = CC16_364, earlychoice = CC16_364b, 
         choice = CC16_364c, vote12 = CC16_326, validated = CL_E2016GVM, weight = commonweight,
         birthyr = birthyr) %>%
  mutate(age = 2016 - birthyr) %>% 
  filter(intent %in% c(1,2,3,4,5)) %>% 
  filter(vote12 %in% c(1,2,3,4,5))

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))
```

## Individual-level turnout

```{r, echo = FALSE}
validation_intent_history <- function(intention, history){
  willvote <- data %>% 
    filter(intent %in% intention, vote12 %in% history 
           #| age <= 22
           )
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First, I'll consider everyone who self-reported that they voted in 2012.

```{r, echo = FALSE, warning = FALSE}
# voted in 2012
mod1 <- validation_intent_history(c(1,3), c(1,2,3))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3))

mods <- list(mod1, mod2, mod3, mod4)

df1 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df1$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df1$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df1$model <- factor(df1$model, levels = df1$model)

# voted in 2012 or don't recall
mod1 <- validation_intent_history(c(1,3), c(1,2,3,5))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3,5))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3,5))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3,5))

mods <- list(mod1, mod2, mod3, mod4)

df2 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df2$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df2$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df2$model <- factor(df2$model, levels = df2$model)

# voted in 2012, don't recall, or didn't vote
mod1 <- validation_intent_history(c(1,3), c(1,2,3,4,5))
mod2 <- validation_intent_history(c(1,2,3), c(1,2,3,4,5))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,2,3,4,5))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df3 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df3$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df3$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df3$model <- factor(df3$model, levels = df3$model)

# create table to output
display <- rbind(df1, df2, df3)
display <- cbind(display, c("Voted in 2012","","","",
                            "Voted in 2012 or don't recall", "","","",
                            "Voted in 2012, don't recall, or didn't vote","","",""))
names(display) <- c("Vote intent","True positive rate","True negative rate",
                    "Vote history")
display <- display %>% select(`Vote history`, `Vote intent`,`True positive rate`,
                              `True negative rate`)
display
```

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_intent <- function(intention, history){
  data %>% 
  filter(intent %in% intention, vote12 %in% history) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}
```

```{r, echo = FALSE}
# voted in 2012
mod1 <- vote_choice_intent(c(1,3), c(1,2,3))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3))

mods <- list(mod1, mod2, mod3, mod4)

df1 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df1$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice=="Trump"]
  i = i + 1
}

df1$model <- factor(df1$model, levels = df1$model)

# voted in 2012 or don't recall
mod1 <- vote_choice_intent(c(1,3), c(1,2,3,5))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3,5))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3,5))

mods <- list(mod1, mod2, mod3, mod4)

df2 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df2$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df2$model <- factor(df2$model, levels = df2$model)

# voted in 2012, don't recall, or did not vote
mod1 <- vote_choice_intent(c(1,3), c(1,2,3,4,5))
mod2 <- vote_choice_intent(c(1,2,3), c(1,2,3,4,5))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,2,3,4,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df3 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df3$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df3$model <- factor(df3$model, levels = df3$model)
```

```{r, echo = FALSE, warning = FALSE}
df_combined <- join_all(list(df1, df2, df3), by = "model")
names(df_combined) <- c("model", "Voted in 2012", "Voted in 2012 or didn't recall", "All")

df_combined %>% gather(`Vote history`, value, `Voted in 2012`:All) %>%  
  ggplot(aes(factor(model), value, fill = `Vote history`)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 30, hjust = 1)) +
  coord_flip() +
  labs(x = "Vote intent", y = "Clinton's predicted margin of victory") +
  scale_fill_grey() +
  geom_hline(yintercept = 2.1, lty = 2, colour = "red")
```

My takeaway is that adding vote history does not add much information on top of vote intent. But this is just for 2016 election predictions - may be useful to predict individual-level turnout and may be useful for other elections still.


# Perry-Gallup index

In their 2016 report on likely voter methodology, the Pew Research Center uses the Perry-Gallup index to measure likelyhood to vote. The questions they use, as well as the response options, are listed below. Response options that are bolded give a respondent a point in the index.

* How much thought have you given to the coming November election? **Quite a lot**, **some**, only a little, none.
* Have you ever voted in your precinct or election district? **Yes**, no.
* Would you say you follow whatâ€™s going on in government and public affairs **most of the time**, **some of the time**, only now and then, hardly at all?
* How often would you say you vote? **Always**, **nearly always**, part of the time, seldom.
* How likely are you to vote in the general election this November? **Definitely will vote**,
**probably will vote**, probably will not vote, definitely will not vote.
* In the 2012 presidential election between Barack Obama and Mitt Romney, did things come up
that kept you from voting, or did you happen to vote? **Yes, voted**; no.
* Please rate your chance of voting in November on a scale of 10 to 1. 0-8, **9**, **10**.

Since the common content of the 2016 CCES does not include all of these survey items (and question wording varies when they do appear), I will attempt to recreate the index using what is available to me. 

The three variables I will consider are vote intent, vote history, and political interest, which capture 5 of the 7 items on the Perry-Gallup index. The one dimension that I will not be able to recreate is self-reported historical voting behavior (voted in precinct before, voting frequency), as this information is not available on the CCES. Here are the CCES questions I will use along with the response options, and how many points each response option gives an individual toward the index. 

* Do you intend to vote in 2016 general election?
    + Yes, definitely (**+2**)
    + Probably (**+1**)
    + I already voted (early or absentee) (**+2**)
    + No
    + Undecided
* In 2012, who did you vote for in the election for President?
    + Barack Obama (**+1**)
    + Mitt Romney (**+1**)
    + Someone else (**+1**)
    + Did not vote
    + Don't recall
* Some people seem to follow what is going on in government or public affairs most of the time, whether there's an election or not. Others aren't that interested. Would you say you follow what is going on in government and public affairs...
    + Most of the time (**+2**)
    + Some of the time (**+1**)
    + Only now and then
    + Hardly at all
    + Don't know

There are two further adjustments I make. First, Pew samples off of a list of registered voters, which the CCES does not do. To compensate, respondents who report that they are registered to vote are given an additional point. Second, since respondents who are younger than 22 would not have had the chance to vote in the previous election, they are given one additional point.

The minimum score, corresponding to those least likely to vote, is 0 while the maximum score, corresponding to those most likely to vote, is 6.

```{r, echo = FALSE, warning = FALSE}
data <- cces16 %>% select(V101, state_abbreviation, CC16_364b, CC16_364c,  
                          CL_E2016GVM, commonweight, CC16_326, CC16_364, newsint, birthyr, votereg) %>% 
  rename(ID = V101, state = state_abbreviation, earlychoice = CC16_364b, choice = CC16_364c, 
         validated = CL_E2016GVM, weight = commonweight, vote12 = CC16_326, intent = CC16_364, 
         interest = newsint, birthyr = birthyr, registration = votereg) %>% 
  mutate(age = 2016 - birthyr) %>% 
  select(-birthyr)

# merge vote choice for early/absentee voters and prospective voters
data <- data %>% 
  mutate(choice = replace(choice, earlychoice == 1, 1)) %>% 
  mutate(choice = replace(choice, earlychoice == 2, 2))

# calculate Perry-Gallup index
data <- data %>% mutate(perry_gallup = 0)

# vote intent
data$perry_gallup[data$intent == 1 | data$intent == 3] <- data$perry_gallup + 2
data$perry_gallup[data$intent == 2]  <- data$perry_gallup + 1

# vote history
data$perry_gallup[data$vote12 == 1 | data$vote12 == 2 | data$vote12 == 3] <- data$perry_gallup + 1

# political interest
data$perry_gallup[!is.na(data$interest) && data$interest == 1] <- data$perry_gallup + 2
data$perry_gallup[!is.na(data$interest) && data$interest == 2] <- data$perry_gallup + 1

# voter registration 
data$perry_gallup[data$registration == 1] <- data$perry_gallup + 1

# age adjustment
data$perry_gallup[data$age < 22 && (data$vote12 == 4 | data$vote12 == 5 | 
                                      data$vote12 == 8 | data$vote12 == 9)] <- data$perry_gallup + 1
```

## Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
validation_by_pg <- function(index) {
  willvote <- data %>% 
    filter(perry_gallup %in% index)
  wontvote <- data %>% 
    anti_join(willvote, by = "ID")

  pred_voters <- willvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = !is.na(validated)) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
mod1 <- validation_by_pg(6)
mod2 <- validation_by_pg(c(6,5))
mod3 <- validation_by_pg(c(6,5,4))
mod4 <- validation_by_pg(c(6,5,4,3))
mod5 <- validation_by_pg(c(6,5,4,3,2))
mod6 <- validation_by_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All"),
                 true_positive = vector(length = 6),
                 true_negative = vector(length = 6))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "rate", title = "Individual level vote validation by Perry-Gallup index score") +
  scale_fill_grey()
```

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_pg <- function(index){
  data %>% 
  filter(perry_gallup %in% index) %>% 
  filter(choice %in% c(1,2) | earlychoice %in% c(1,2)) %>% 
  mutate(choice = replace(choice, choice == 1, "Trump")) %>% 
  mutate(choice = replace(choice, choice == 2, "Clinton")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

mod1 <- vote_choice_pg(6)
mod2 <- vote_choice_pg(c(6,5))
mod3 <- vote_choice_pg(c(6,5,4))
mod4 <- vote_choice_pg(c(6,5,4,3))
mod5 <- vote_choice_pg(c(6,5,4,3,2))
mod6 <- vote_choice_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All"),
                 margin = vector(length = 6))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Clinton"] - mods[[i]]$vote_share[mods[[i]]$choice == "Trump"]
  i = i + 1
}

df$model <- factor(df$model, levels = df$model)

df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  labs(y = "Clinton's predicted margin of victory") +
  geom_hline(yintercept = 2.1, lty = 2, colour = "red")
```



# Logistic Regression

For this section I will begin using the cumulative CCES file. I'll consider three sets of variables:

* Perry-Gallup index
* Perry-Gallup index + all variables potentially related to turnout
* Perry-Gallup + all variables potentially related to turnout + structural election variables

Note that when I just consider the Perry-Gallup index I do make a similar adjustment for age and registration. For age, I define a variable `eligible` that is coded 1 if a respondent was old enough to vote in 2012, or is 22 or older now, and coded 0 if a respondent was not old enough to vote in 2012, or is younger than 22 now. For registration, I recode the variable to be 1 if the respondent reported that they were registered to vote and 0 if they reported that they were not registered or if they did not know.

## Perry-Gallup index

```{r, echo = FALSE, warning = FALSE}
# # training set = pooled data from 2012 and 2008
# train <- pooled %>% filter(year %in% c(2008, 2012))
# test <- pooled %>% filter(year == 2016)
# 
# # exclude Rs who weren't asked these questions in train...
# train <- train[train$vote12 < 8,] 
# train <- train[train$intent < 8,]
# train <- train[train$interest < 8,]
# 
# # ... and test
# test <- test[test$vote12 < 8,] 
# test <- test[test$intent < 8,]
# test <- test[test$interest < 8,]
# 
# # recode vote12 so that we capture whether someone voted or not and not for who for train...
# train$vote12[train$vote12 == 1 | train$vote12 == 2 | train$vote12 == 3] <- 1
# train$vote12[train$vote12 == 4 | train$vote12 == 5] <- 2
# 
# # ... and test
# test$vote12[test$vote12 == 1 | test$vote12 == 2 | test$vote12 == 3] <- 1
# test$vote12[test$vote12 == 4 | test$vote12 == 5] <- 2
# 
# # recode interest to put 'Don't know' responses as 'Hardly at all'
# train$interest[train$interest == 7] <- 4
# test$interest[test$interest == 7] <- 4
# 
# # set all categorical variables as factors
# train <- train %>% mutate(validated = as.factor(validated),
#                  vote12 = as.factor(vote12),
#                  intent = as.factor(intent),
#                  interest = as.factor(interest),
#                  registration = as.factor(registration))
# test <- test %>% mutate(validated = as.factor(validated),
#                  vote12 = as.factor(vote12),
#                  intent = as.factor(intent),
#                  interest = as.factor(interest),
#                  registration = as.factor(registration))
# 
# # run unweighted model
# formula <- as.formula(validated ~ vote12 + intent + interest + registration)
# model_unweighted <- glm(formula, family = binomial(link = "logit"), data = train)
#   
# # run weighted model
# svy.train <- svydesign(ids = ~ 1, data = train, weights = ~weight)
# model_weighted <- svyglm(formula, design = svy.train, family = binomial)
# 
# # apply the models to test data
# # unweighted
# predictions_unweighted <- cbind(test, predict(model_unweighted, newdata = test, type = "response"))
# predictions_unweighted <- as.data.frame(predictions_unweighted)
# # weighted
# predictions_weighted <- cbind(test, predict(model_weighted, newdata = test, type = "response"))
# predictions_weighted <- as.data.frame(predictions_weighted)
```


### Individual-level turnout

```{r, echo = FALSE}
# For the Perry-Gallup regression and RF sections I should make an age and RV adjustment. For age, make two categories: eligible to vote in previous election or not (i.e., age over or under 22). And then a similar one for RVs versus non-RVs.
# 
# I will not be considering the political activism/interest items of reading newspaper or watching tv anymore --> imputation doesn't make sense because I'm missing so much of it and not randomly (i.e., don't have any for 2012).
# 
# Consider weighted and unweighted regression in this section.
# -2008 + 2012
# --weighted
# --unweighted
# 
# -if no real differences I do not need to show both sets of graphs, can just explain
# 
# -overlay histograms of propensity scores for treatment and control to see if we have balance and overlap!!!!

#going to have to recode vote history
```
