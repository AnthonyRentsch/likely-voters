---
title: "Analysis Part I - National Models"
date: "April 25, 2018"
output:
  github_document:
    toc: true
    #toc_float: true
    toc_depth: 2
    #collapsed: false
    #smooth_scroll: false
    df_print: kable
---

```{r setup, echo = FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::read_chunk('load.R')
```

```{r, echo = FALSE, include = FALSE}
# run load.R 
 <<load>> 
```

# Introduction

In this document, I will define and create the cutoff models that I will use for my analysis and then evaluate their performance. The sections will proceed as follows:

* Vote intent
* Vote intent + vote history
* Perry-Gallup index
* Logistic regression
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
* Random forests
    + Perry-Gallup
    + Perry-Gallup + all variables potentially related to turnout 
    + Perry-Gallup + all variables potentially related to turnout + structural election variables
  
In each section I will create a model and then evaluate how well it predicts voting behavior on an individual-level. At the end, I will use these models to make election predictions.



# Vote Intent

For this section (and the next two), I only need to use 2016 data until. I treat people who report that they have already voted the same as people who report that they definitely plan to vote. Note that the weight I use -- which comes from the cumulative CCES file -- combines weights based on age, gender, education, race, voter registration, ideology, baseline party identification, born again status, and political interest.


## Individual-level turnout

```{r, echo = FALSE}
validation_by_intent <- function(intention){
  willvote <- pooled %>% 
    filter(year == 2016, intent %in% intention)
  wontvote <- pooled %>% filter(year == 2016) %>% 
    anti_join(willvote, by = 'case_id')

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First we compare individual-level turnout prediction accuracy when we define likely voters as:

* those who say they will definitely vote or have voted already
* those who say they will definitely vote, have voted already, or will probably vote
* those who say they will definitely vote, have voted already, will probably vote, or who are undecided
* all respondents in the sample

where:

* true positive rate = rate at which predicted voters are validated as voters
* true negative rate = rate at which predicted nonvoters are not validated as voters

```{r, echo = FALSE, warning = FALSE}
# those who say they will definitely vote or have voted already
mod1 <- validation_by_intent(c(1,3))
# those who say they will definitely vote, have voted already, or will probably vote
mod2 <- validation_by_intent(c(1,2,3))
# those who say they will definitely vote, have voted already, will probably vote, or who are undecided
mod3 <- validation_by_intent(c(1,2,3,5))
# all respondents in the sample
mod4 <- validation_by_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 #false_positive = vector(length = 5),
                 #false_negative = vector(length = 5),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  #df$false_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "No"]
  #df$false_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  mutate(type = replace(type, type == 'true_positive', 'True positive'),
         type = replace(type, type == 'true_negative', 'True negative')) %>% 
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "", y = "", title = "Individual level vote validation by vote intent") +
  scale_fill_grey() +
  theme(legend.title=element_blank())
```


## Election predictions


```{r, echo = FALSE}
vote_choice_intent <- function(intention){
  pooled %>% 
  filter(year == 2016, intent %in% intention) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(100*n/sum(n),2)) %>% 
  select(-n)
}
```

Now we compare election predictions, using the same likely voter models as specified above.

```{r, echo = FALSE}
mod1 <- vote_choice_intent(c(1,3))
mod2 <- vote_choice_intent(c(1,2,3))
mod3 <- vote_choice_intent(c(1,2,3,5))
mod4 <- vote_choice_intent(c(1,2,3,4,5))

mods <- list(mod1, mod2, mod3, mod4)

df <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Hillary Clinton (Democrat)"] - mods[[i]]$vote_share[mods[[i]]$choice == "Donald Trump (Republican)"]
  i = i + 1
}

df$model <- factor(df$model, levels = df$model)

fig1 <- df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  geom_hline(yintercept = validated_margin16, lty = 2, size = 1, colour = "red") +
  labs(x = "", y = "Clinton's predicted margin of victory")
fig1
```



# Vote Intent + Vote History

Let's move on to the next baseline model - using vote history and vote intent. I follow the same template from above but consider what happens when likely voters are defined as individuals who report that they voted in the previous presidential election (2012) as well as what happens when we do not make that distinction.

Note that this will necessarily exclude any respondent who was too young to vote in 2012 (unless they lie on this question, of course).


## Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
validation_intent_history <- function(intention, history){
  willvote <- pooled %>% 
    filter(year == 2016, intent %in% intention, vote_history %in% history, age >= 22)
  wontvote <- pooled %>% filter(year == 2016, age >= 22) %>% 
    anti_join(willvote, by = "case_id")
  # add voters ineligible to vote in 2012
  ineligible_voters12_willvote <- pooled %>% filter(age < 22, intent %in% intention)
  ineligible_voters12_wontvote <- pooled %>% filter(age < 22) %>% 
    anti_join(ineligible_voters12_willvote, by = "case_id")
  
  willvote <- rbind(willvote, ineligible_voters12_willvote)
  wontvote <- rbind(wontvote, ineligible_voters12_wontvote)

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
```

First, I'll consider everyone who self-reported that they voted in 2012. Then I'll consider everyone who self-reported that they voted in 2012 and those that reported that they did not vote or that they do not remember.

```{r, echo = FALSE, warning = FALSE}
# voted in 2012
mod1 <- validation_intent_history(c(1,3), c(1))
mod2 <- validation_intent_history(c(1,2,3), c(1))
mod3 <- validation_intent_history(c(1,2,3,5), c(1))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1))

mods <- list(mod1, mod2, mod3, mod4)

df1 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df1$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df1$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df1$model <- factor(df1$model, levels = df1$model)

# voted in 2012, don't recall, or didn't vote
mod1 <- validation_intent_history(c(1,3), c(1,0))
mod2 <- validation_intent_history(c(1,2,3), c(1,0))
mod3 <- validation_intent_history(c(1,2,3,5), c(1,0))
mod4 <- validation_intent_history(c(1,2,3,4,5), c(1,0))

mods <- list(mod1, mod2, mod3, mod4)

df2 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 true_positive = vector(length = 4),
                 true_negative = vector(length = 4))
i <- 1
while(i <= length(mods)){
  df2$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df2$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df2$model <- factor(df2$model, levels = df2$model)

# create table to output
display <- rbind(df1, df2)
display <- cbind(display, c("Voted in 2012","","","",
                            "Voted in 2012, don't recall, or didn't vote","","",""))
names(display) <- c("Vote intent","True positive rate","True negative rate",
                    "Vote history")
display <- display %>% select(`Vote history`, `Vote intent`,`True positive rate`,
                              `True negative rate`)
display
```

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_intent <- function(intention, history){
  voters_eligible12 <- pooled %>% 
    filter(year == 2016, intent %in% intention, vote_history %in% history, age >= 22) 
  voters_ineligible12 <- pooled %>% 
    filter(year == 2016, intent %in% intention, age < 22) 
  voters <- rbind(voters_eligible12, voters_ineligible12)
  
 voters %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(100*n/sum(n),2)) %>% 
  select(-n)
}
```

```{r, echo = FALSE}
# voted in 2012
mod1 <- vote_choice_intent(c(1,3), 1)
mod2 <- vote_choice_intent(c(1,2,3), 1)
mod3 <- vote_choice_intent(c(1,2,3,5), 1)
mod4 <- vote_choice_intent(c(1,2,3,4,5), 1)

mods <- list(mod1, mod2, mod3, mod4)

df1 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df1$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Hillary Clinton (Democrat)"] - mods[[i]]$vote_share[mods[[i]]$choice == "Donald Trump (Republican)"]
  i = i + 1
}

df1$model <- factor(df1$model, levels = df1$model)

# voted in 2012, don't recall, or did not vote
mod1 <- vote_choice_intent(c(1,3), c(1,0))
mod2 <- vote_choice_intent(c(1,2,3), c(1,0))
mod3 <- vote_choice_intent(c(1,2,3,5), c(1,0))
mod4 <- vote_choice_intent(c(1,2,3,4,5), c(1,0))

mods <- list(mod1, mod2, mod3, mod4)

df2 <- data.frame(model = c("Already voted + will definitely vote", "Already voted + will definitely or probably vote", "Already voted + will definitely or probably vote + undecided", "All respondents"),
                 margin = vector(length = 4))

i <- 1
while(i <= length(mods)){
  df2$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Hillary Clinton (Democrat)"] - mods[[i]]$vote_share[mods[[i]]$choice == "Donald Trump (Republican)"]
  i = i + 1
}

df2$model <- factor(df2$model, levels = df2$model)
```

```{r, echo = FALSE, warning = FALSE}
df_combined <- join_all(list(df1, df2), by = "model")
names(df_combined) <- c("model", "Voted in 2012", "All")

fig3 <- df_combined %>% gather(`Vote history`, value, `Voted in 2012`:All) %>%  
  ggplot(aes(factor(model), value, fill = `Vote history`)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 30, hjust = 1)) +
  coord_flip() +
  labs(x = "", y = "Clinton's predicted margin of victory") +
  scale_fill_grey() +
  geom_hline(yintercept = validated_margin16, lty = 2, size = 1, colour = "red")
fig3
```

My takeaway is that adding vote history does not add much information on top of vote intent. But this is just for 2016 election predictions - may be useful to predict individual-level turnout and may be useful for other elections still.


# Perry-Gallup index

In their 2016 report on likely voter methodology, the Pew Research Center uses the Perry-Gallup index to measure likelyhood to vote. The questions they use, as well as the response options, are listed below. Response options that are bolded give a respondent a point in the index.

* How much thought have you given to the coming November election? **Quite a lot**, **some**, only a little, none.
* Have you ever voted in your precinct or election district? **Yes**, no.
* Would you say you follow whatâ€™s going on in government and public affairs **most of the time**, **some of the time**, only now and then, hardly at all?
* How often would you say you vote? **Always**, **nearly always**, part of the time, seldom.
* How likely are you to vote in the general election this November? **Definitely will vote**,
**probably will vote**, probably will not vote, definitely will not vote.
* In the 2012 presidential election between Barack Obama and Mitt Romney, did things come up
that kept you from voting, or did you happen to vote? **Yes, voted**; no.
* Please rate your chance of voting in November on a scale of 10 to 1. 0-8, **9**, **10**.

Since the common content of the 2016 CCES does not include all of these survey items (and question wording varies when they do appear), I will attempt to recreate the index using what is available to me. 

The three variables I will consider are vote intent, vote history, and political interest, which capture 5 of the 7 items on the Perry-Gallup index. The one dimension that I will not be able to recreate is self-reported historical voting behavior (voted in precinct before, voting frequency), as this information is not available on the CCES. Here are the CCES questions I will use along with the response options, and how many points each response option gives an individual toward the index. 

* Do you intend to vote in 2016 general election?
    + Yes, definitely (**+2**)
    + Probably (**+1**)
    + I already voted (early or absentee) (**+2**)
    + No
    + Undecided
* Did you vote in the 2012 general election?
    + Yes (**+1**)
    + No
* Some people seem to follow what is going on in government or public affairs most of the time, whether there's an election or not. Others aren't that interested. Would you say you follow what is going on in government and public affairs...
    + Most of the time (**+2**)
    + Some of the time (**+1**)
    + Only now and then
    + Hardly at all
    + Don't know

There are two further adjustments I make. First, Pew samples off of a list of registered voters, which the CCES does not do. To compensate, respondents who report that they are registered to vote are given an additional point. Second, since respondents who are younger than 22 would not have had the chance to vote in the previous election, they are given one additional point.

The minimum score, corresponding to those least likely to vote, is 0 while the maximum score, corresponding to those most likely to vote, is 6.

## Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
validation_by_pg <- function(index) {
  willvote <- pooled %>% 
    filter(year == 2016, perry_gallup %in% index)
  wontvote <- pooled %>% filter(year == 2016) %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}
mod1 <- validation_by_pg(6)
mod2 <- validation_by_pg(c(6,5))
mod3 <- validation_by_pg(c(6,5,4))
mod4 <- validation_by_pg(c(6,5,4,3))
mod5 <- validation_by_pg(c(6,5,4,3,2))
mod6 <- validation_by_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All"),
                 true_positive = vector(length = 6),
                 true_negative = vector(length = 6))
i <- 1
while(i <= length(mods)){
  df$true_positive[i] <- mods[[i]]$voters[mods[[i]]$validated == "Yes"]
  df$true_negative[i] <- mods[[i]]$nonvoters[mods[[i]]$validated == "No"]
  i = i +1
}
                 
df$model <- factor(df$model, levels = df$model)

df %>% gather(type, value, true_positive:true_negative) %>%
  mutate(type = replace(type, type == 'true_positive', 'True positive rate'),
         type = replace(type, type == 'true_negative', 'True negative rate')) %>% 
  ggplot(aes(factor(model), value, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "model", y = "", title = "Individual level vote validation by Perry-Gallup index score") + 
  scale_fill_grey() +
  theme(legend.title=element_blank())
```

## Election predictions

```{r, echo = FALSE, warning = FALSE}
vote_choice_pg <- function(index){
  pooled %>% 
  filter(year == 2016, perry_gallup %in% index) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

mod1 <- vote_choice_pg(6)
mod2 <- vote_choice_pg(c(6,5))
mod3 <- vote_choice_pg(c(6,5,4))
mod4 <- vote_choice_pg(c(6,5,4,3))
mod5 <- vote_choice_pg(c(6,5,4,3,2))
mod6 <- vote_choice_pg(c(6,5,4,3,2,1))

mods <- list(mod1, mod2, mod3, mod4, mod5, mod6)

df <- data.frame(model = c("6s","6s and 5s","6s, 5s, and 4s","6s, 5s, 4s, and 3s", 
                           "6s, 5s, 4s, 3s, and 2s","All"),
                 margin = vector(length = 6))

i <- 1
while(i <= length(mods)){
  df$margin[i] = mods[[i]]$vote_share[mods[[i]]$choice == "Hillary Clinton (Democrat)"] - mods[[i]]$vote_share[mods[[i]]$choice == "Donald Trump (Republican)"]
  i = i + 1
}

df$model <- factor(df$model, levels = df$model)

fig5 <- df %>%  
  ggplot() +
  geom_col(aes(model, margin)) +
  coord_flip() +
  labs(x = "", y = "Clinton's predicted margin of victory") +
  geom_hline(yintercept = validated_margin16, lty = 2, size = 1, colour = "red")
fig5
```




# Logistic Regression

For this section I will begin using the cumulative CCES file. I'll consider three sets of variables:

* Perry-Gallup index
* Perry-Gallup index + all variables potentially related to turnout
* Perry-Gallup index + all variables potentially related to turnout + structural election variables

Note that when I just consider the Perry-Gallup index I do make a similar adjustment for age and registration. For age, I define a variable `eligible` that is coded 1 if a respondent was old enough to vote in the previous presidential election and coded 0 if a respondent was not old enough to vote in the previous election. For registration, I recode the variable to be 1 if the respondent reported that they were registered to vote and 0 if they reported that they were not registered or if they did not know.

## Perry-Gallup index

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# run unweighted model
formula <- as.formula(validated ~ vote_history*intent + interest + 
                        registration + eligible)
model <- glm(formula, family = binomial(link = "logit"), data = train)

# run weighted model
svy.train <- svydesign(ids = ~ 1, data = train, weights = ~weight)
model_weighted <- svyglm(formula, design = svy.train, family = binomial)

# apply the models to test data
# unweighted
predictions <- cbind(test, predict(model, newdata = test, type = "response"))
predictions <- as.data.frame(predictions)
predictions<- predictions %>% 
  rename(response = 'predict(model, newdata = test, type = \"response\")')
# weighted
# predictions_weighted <- cbind(test, predict(model_weighted, newdata = test, type = "response"))
# predictions_weighted <- as.data.frame(predictions_weighted)
```


### Individual-level turnout

```{r, echo = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = response), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = response)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig7a <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "a. Perry-Gallup index",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig7a
```

### Election Predictions

Note that I include two calculations here: in one, I consider the margin of victory for Clinton only weighted by the weighting variable included in the pooled CCES while in the other I consider the margin weighted by that weight times the vote propensity score from the model.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*response)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig8a <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(93, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
                #label = "weighted margin", vjust = -1)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(89.5, validated_margin16, label = "validated voter margin", vjust = -1)) +
  labs(title = "a. Perry-Gallup index",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") +
  theme(plot.title = element_text(hjust = 0.5))
fig8a
```


## Perry-Gallup index + all variables potentially related to turnout

This next model considers the Perry-Gallup index variables mentioned in the previous section in addition to a whole slew of demographic variables that literature has suggested may be tied to turnout or to misreporting voting intention. These include:

* Age
* Race
* Education
* Income
* Partisan strength
* Religiosity
* Marital status
* Residential mobility
* ~~Racial composition of district~~
* ~~Political interest/activism~~
    + ~~Watching news~~
    + ~~Reading newspaper~~
    
The racial composition of district and political interest/activism items are not included in my model because they are not widely available on the CCES surveys I consider.

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# run unweighted model
formula <- as.formula(validated ~ vote_history*intent + interest + registration + 
                        gender + age + race + education + income_new + 
                        partisan_strength + religiosity + marital_status +
                        residential_mobility)
model <- glm(formula, family = binomial(link = "logit"), data = train)

# run weighted model
# svy.train <- svydesign(ids = ~ 1, data = train, weights = ~weight)
# model_weighted <- svyglm(formula, design = svy.train, family = binomial)

# apply the models to test data
# unweighted
predictions <- cbind(test, predict(model, newdata = test, type = "response"))
predictions <- as.data.frame(predictions)
predictions <- predictions %>% 
  rename(response = 'predict(model, newdata = test, type = \"response\")')
# weighted
# predictions_weighted <- cbind(test, predict(model_weighted, newdata = test, type = "response"))
# predictions_weighted <- as.data.frame(predictions_weighted)
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = response), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = response)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig7b <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "b. Perry-Gallup index + all variables potentially related to turnout",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig7b
```

### Election Predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*response)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig8b <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(93, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
                #label = "weighted margin", vjust = -1)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(89.5, validated_margin16, label = "validated voter margin", vjust = -1)) +
  labs(title = "b. Perry-Gallup index + all variables potentially related to turnout",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") + 
  theme(plot.title = element_text(hjust = 0.5))
fig8b
```


## Perry-Gallup index + all variables potentially related to turnout + structural election variables

In addtion to the variables I included in the last mode, I now include structural election variables. I use a reformulation of Abramowitz's Time-for-Change model. The model predicts the vote share for the candidate of the incumbent's party based on 

* the net approval rating of the sitting President (using the final Gallup poll in June of the election year) 
* the annualized growth rate of real GDP in the second quarter of the election year (taken from the U.S. Department of Commerce's Bureau of Economic Analysis)
* whether a first-term incumbent is running
    + Since I also use midterm election years, I consider whether the incumbent and the President are from the same party (this is coded 1 in presidential election years and 1 or 0 in midterm years)
* an indicator variable to measure the level of polarization (this was added in 2012): it is coded
    + 1 if first-term incumbent running or open seat where incumbent president has net approval rating over 0 (presidential election years) or 1 if the House incumbent is from the same party as the President or if they are from different parties and the President has a net approval rating over 0 (midterm election years)
    + 0 if no first-term incumbent or incumbent president has net approval rating less than 0 (presidential election years) or 0 if the House incumbent and President are from different parties and the presidential net approval rating is less than 0 (midterm election years)

You can read more about his model [here](https://www.washingtonpost.com/blogs/ezra-klein/files/2012/08/abramowitz.pdf).

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# run unweighted model
formula <- as.formula(validated ~ vote_history*intent + interest + registration + 
                        gender + age + race + education + income_new + 
                        partisan_strength + religiosity + marital_status +
                        residential_mobility + gdp_growth*approval*incumbent*polarization)
model <- glm(formula, family = binomial(link = "logit"), data = train)

# run weighted model
# svy.train <- svydesign(ids = ~ 1, data = train, weights = ~weight)
# model_weighted <- svyglm(formula, design = svy.train, family = binomial)

# apply the models to test data
# unweighted
predictions <- cbind(test, predict(model, newdata = test, type = "response"))
predictions <- as.data.frame(predictions)
predictions <- predictions %>% 
  rename(response = 'predict(model, newdata = test, type = \"response\")')
# weighted
# predictions_weighted <- cbind(test, predict(model_weighted, newdata = test, type = "response"))
# predictions_weighted <- as.data.frame(predictions_weighted)
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = response), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = response)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig7c <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "c. Perry-Gallup index + all variables potentially related to turnout \n + structural election variables",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig7c
```

### Election Predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = response) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*response)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig8c <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(93, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
                #label = "weighted margin", vjust = -1)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(89.5, validated_margin16, label = "validated voter margin", vjust = -1)) +
  labs(title = "c. Perry-Gallup index + all variables potentially related to turnout \n + structural election variables",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") +
  theme(plot.title = element_text(hjust = 0.5))
fig8c
```


# Random Forests

For this section I will proceed as I did in the last section, except now I use random forest models instead of logistic regression models. Again, the layout will be:

* Perry-Gallup index
* Perry-Gallup index + all variables potentially related to turnout
* Perry-Gallup index + all variables potentially related to turnout + structural election variables


## Perry-Gallup index

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# create eligible variable
# train
train$eligible[train$year %in% c(2008, 2012) & train$age < 22] <- 0
train$eligible[train$year %in% c(2008, 2012) & train$age >= 22] <- 1
train$eligible[train$year %in% c(2010, 2014) & train$age < 20] <- 0
train$eligible[train$year %in% c(2010, 2014) & train$age >= 20] <- 1
# test
test$eligible[test$age < 22] <- 0
test$eligible[test$age >= 22] <- 1

# run model
formula <- as.formula(validated ~ vote_history + intent + interest + registration + 
                        eligible)
model <- randomForest(formula, data = train)

# apply the models to test data
predictions <- cbind(test, predict(model, newdata = test, type = "prob"))
predictions <- as.data.frame(predictions)
```


### Individual-level turnout

```{r, echo = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = Voted), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = Voted)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig11a <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "a. Perry-Gallup index",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig11a
```

### Election Predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*Voted)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig12a <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(95, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
               # label = "weighted margin", vjust = -1)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(91, validated_margin16, label = "validated voter margin", vjust = -1)) +
  labs(title = "a. Perry-Gallup index",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") +
  theme(plot.title = element_text(hjust = 0.5))
fig12a
```

## Perry-Gallup index + all variables potentially related to turnout

This next model considers the Perry-Gallup index variables mentioned in the previous section in addition to a whole slew of demographic variables that literature has suggested may be tied to turnout or to misreporting voting intention. These include:

* Age
* Race
* Education
* Income
* Partisan strength
* Religiosity
* Marital status
* Residential mobility
* ~~Racial composition of district~~
* ~~Political interest/activism~~
    + ~~Watching news~~
    + ~~Reading newspaper~~
    
The racial composition of district and political interest/activism items are not included in my model because they are not widely available on the CCES surveys I consider.

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# run model
formula <- as.formula(validated ~ vote_history + intent + interest + registration + 
                        gender + age + race + education + income_new + 
                        partisan_strength + religiosity + marital_status +
                        residential_mobility)
model <- randomForest(formula, data = train)

# apply the models to test data
predictions <- cbind(test, predict(model, newdata = test, type = "prob"))
predictions <- as.data.frame(predictions)
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = Voted), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 0.99 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = Voted)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig11b <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "b. Perry-Gallup index + all variables potentially related to turnout",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig11b
```

### Election Predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*Voted)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig12b <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(93, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
               # label = "weighted margin", vjust = 2)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(89.5, validated_margin16, label = "validated voter margin", vjust = -1)) +
  labs(title = "b. Perry-Gallup index + all variables potentially related to turnout",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") +
  theme(plot.title = element_text(hjust = 0.5))
fig12b
```


## Perry-Gallup index + all variables potentially related to turnout + structural election variables

In addtion to the variables I included in the last mode, I now include structural election variables. I use a reformulation of Abramowitz's Time-for-Change model. The model predicts the vote share for the candidate of the incumbent's party based on 

* the net approval rating of the sitting President (using the final Gallup poll in June of the election year) 
* the annualized growth rate of real GDP in the second quarter of the election year (taken from the U.S. Department of Commerce's Bureau of Economic Analysis)
* whether a first-term incumbent is running
    + Since I also use midterm election years, I consider whether the incumbent and the President are from the same party (this is coded 1 in presidential election years and 1 or 0 in midterm years)
* an indicator variable to measure the level of polarization (this was added in 2012): it is coded
    + 1 if first-term incumbent running or open seat where incumbent president has net approval rating over 0 (presidential election years) or 1 if the House incumbent is from the same party as the President or if they are from different parties and the President has a net approval rating over 0 (midterm election years)
    + 0 if no first-term incumbent or incumbent president has net approval rating less than 0 (presidential election years) or 0 if the House incumbent and President are from different parties and the presidential net approval rating is less than 0 (midterm election years)

You can read more about his model [here](https://www.washingtonpost.com/blogs/ezra-klein/files/2012/08/abramowitz.pdf).

```{r, echo = FALSE, warning = FALSE}
# create training set 
train <- pooled %>% filter(year %in% c(2008,2010,2012,2014))
test <- pooled %>% filter(year == 2016)

# run model
formula <- as.formula(validated ~ vote_history + intent + interest + registration + 
                        gender + age + race + education + income_new + 
                        partisan_strength + religiosity + marital_status +
                        residential_mobility + gdp_growth + approval + incumbent +
                        polarization)
model <- randomForest(formula, data = train, na.action = na.omit)

# apply the models to test data
predictions <- cbind(test, predict(model, newdata = test, type = "prob"))
predictions <- as.data.frame(predictions)
```

### Individual-level turnout

```{r, echo = FALSE, warning = FALSE}
ggplot(predictions) +
  geom_histogram(aes(x = Voted), position = "identity", bins = 20) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = paste0("Predicted vote propensity scores for 2016 CCES holdout sample (N = ",
                      nrow(predictions), ")", sep = ""),
       x = "Vote propensity score")
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# consider turnout rates from 0.01 to 1 by 1
turnout_rates <- seq(from = 0.01, to = 1, by = 0.01)

# calculate true positive and negative rates for each level of turnout
validation_by_logreg <- function(turnout){
  willvote <- predictions %>% 
    top_n(round(nrow(predictions)*turnout,0), wt = Voted)
  wontvote <- predictions %>% 
    anti_join(willvote, by = "case_id")

  pred_voters <- willvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  pred_nonvoters <- wontvote %>% 
    count(validated = (validated == 'Voted')) %>% 
    mutate(percent = round((n/sum(n))*100,2)) %>% 
    mutate(validated = replace(validated, validated == "FALSE", "No")) %>% 
    mutate(validated = replace(validated, validated == "TRUE", "Yes")) %>% 
    select(-n)
  
  left_join(pred_voters, pred_nonvoters, by = "validated", suffix = c("_v","_nv")) %>% 
    rename(voters = percent_v, nonvoters = percent_nv)
}

true_pos_neg_rates_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- validation_by_logreg(turnout_rates[i])
   true_pos_neg_rates_by_turnout[i,1] <- temp$voters[temp$validated=="Yes"]
   true_pos_neg_rates_by_turnout[i,2] <- temp$nonvoters[temp$validated=="No"]
   true_pos_neg_rates_by_turnout[i,3] <- i
   i = i +1
}

# plot lines for the two rates
fig11c <- true_pos_neg_rates_by_turnout %>% 
  rename(true_positive = V1, true_negative = V2, i = V3) %>% 
  ggplot() +
  geom_line(aes(x = turnout_rates[i]*100, y = true_positive, lty = "True positive")) +
  geom_line(aes(x = turnout_rates[i]*100, y = true_negative, lty = "True negative")) +
  #geom_vline(xintercept = 60.2, lty = 4) +
  labs(title = "c. Perry-Gallup index + all variables potentially related to turnout \n + structural election variables",
       x = "Turnout rate (%)",
       y = "",
       lty = "Type") +
    theme(legend.title=element_blank(),
          plot.title = element_text(hjust = 0.5))
fig11c
```

### Election Predictions

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# no propensity weight for margin
vote_choice_logreg <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg(turnout_rates[i])
   margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   margin_by_turnout[i,2] <- i
   i = i +1
}

# margin weighted by propensity score
vote_choice_logreg_weighted <- function(turnout){
  predictions %>% 
  top_n(round(nrow(predictions)*turnout,0), wt = Voted) %>% 
  filter(choice %in% c("Donald Trump (Republican)","Hillary Clinton (Democrat)",
                       "Gary Johnson (Libertarian)","Jill Stein (Green)","Other",
                       "I'm Not Sure")) %>% 
  group_by(choice) %>% 
  summarise(n = sum(weight*Voted)) %>% 
  mutate(vote_share = round(n/sum(n)*100,2)) %>% 
  select(-n)
}

weighted_margin_by_turnout <- data.frame()
i <- 1
while(i <= length(turnout_rates)){
   temp <- vote_choice_logreg_weighted(turnout_rates[i])
   weighted_margin_by_turnout[i,1] <- temp$vote_share[temp$choice=='Hillary Clinton (Democrat)'] - temp$vote_share[temp$choice=='Donald Trump (Republican)']
   weighted_margin_by_turnout[i,2] <- i
   i = i +1
}

# visualize
margin_by_turnout <- margin_by_turnout %>% rename(margin = V1, i = V2)
weighted_margin_by_turnout <- weighted_margin_by_turnout %>% rename(margin = V1, i = V2)

fig12c <- ggplot() +
  geom_point(data = margin_by_turnout, 
             aes(x = turnout_rates[i]*100, y = margin), colour = "grey", alpha = 0.8) +
  geom_hline(yintercept = 
               weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100], 
             lty = 2, col = "black") +
  #geom_text(aes(93, weighted_margin_by_turnout$margin[weighted_margin_by_turnout$i == 100],
              #  label = "weighted margin", vjust = 3.5)) +
  geom_hline(yintercept = validated_margin16, lty = 2, col = "red") +
  #geom_text(aes(91, validated_margin16, label = "validated voter margin", vjust = -2.5)) +
  labs(title = "c. Perry-Gallup index + all variables potentially related to turnout \n + structural election variables",
       x = "Turnout (%)",
       y = "Clinton's predicted margin of victory") +
  theme(plot.title = element_text(hjust = 0.5))
fig12c
```

